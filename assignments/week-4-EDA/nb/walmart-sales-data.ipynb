{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05ff2061",
   "metadata": {},
   "source": [
    "<p align = \"center\" draggable=”false” ><img src=\"https://user-images.githubusercontent.com/37101144/161836199-fdb0219d-0361-4988-bf26-48b0fad160a3.png\" \n",
    "     width=\"200px\"\n",
    "     height=\"auto\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bda3da",
   "metadata": {},
   "source": [
    "# <h1 align=\"center\" id=\"heading\">EDA with Walmart Sales</h1>\n",
    "\n",
    "## Business Objective\n",
    "\n",
    "Walmart, the retail giant that operates a chain of hypermarkets, wants to understand their weekly sales data, especially the impact from holidays and or big events on the weekly sales data; specifically, Super Bowl, Labor Day, Thanksgiving, and Christmas. In addition, Walmart wants to consider the effect from different macroeconomic/external factors. \n",
    "\n",
    "##  ☑️ Learning Objectives\n",
    "At the end of this session, you will know how to\n",
    "\n",
    "1. Manipulate data of different types using `pandas`\n",
    "1. Visualize data with `matplotlib` and `seaborn` to Extract insights \n",
    "1. Build a pipeline to preprocess data and fit a simple model using `sklearn`\n",
    "\n",
    "*Note: if you see code that's unfamiliar to you, look up for the documentation, and try to understand what it does.*\n",
    "\n",
    "## Pre-Work\n",
    "1. activate your `conda` environment; replace `py39_12` with the name of your `conda` environment (`conda env list` to see all available environments)\n",
    "    ```\n",
    "    conda activate py39_12\n",
    "    ```\n",
    "2. install the required packages under the current directory: `{Your Local Directory}/MLE-8/assignments/eda-walmart-sales/`\n",
    "    ```\n",
    "    pip install -r requirements.txt\n",
    "    ```\n",
    "    *NB: requirements.txt contains the following:*\n",
    "    numpy \n",
    "    pandas\n",
    "    scipy\n",
    "    matplotlib \n",
    "    seaborn \n",
    "    scikit-learn==1.0.2\n",
    "    sweetviz==2.1.4\n",
    "    \n",
    "3. Launch jupyter notebook or jupyter lab\n",
    "    ```\n",
    "    jupyter notebook # or jupyter lab\n",
    "    ```\n",
    "4. Run notebook [imports](nb/imports.ipynb) and make sure no error messages are displayed when importing the packages. \n",
    "\n",
    "## Background\n",
    "Please review the weekly narrative [here](https://great-yamamomo-5c3.notion.site/Week-4-Data-Engineering-9cd074e33a46401da011cc2d8b2a0d2e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42734778",
   "metadata": {},
   "source": [
    "## Sanity check\n",
    "*Run notebook imports:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf5d7aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np      \n",
    "import pandas as pd     \n",
    "\n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3cd28c",
   "metadata": {
    "papermill": {
     "duration": 0.15014,
     "end_time": "2022-05-14T21:23:05.759231",
     "exception": false,
     "start_time": "2022-05-14T21:23:05.609091",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# EDA with Walmart Sales Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e041d2",
   "metadata": {
    "papermill": {
     "duration": 0.127394,
     "end_time": "2022-05-14T21:23:06.801644",
     "exception": false,
     "start_time": "2022-05-14T21:23:06.674250",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Business Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da80ebbe",
   "metadata": {
    "papermill": {
     "duration": 0.129918,
     "end_time": "2022-05-14T21:23:07.060222",
     "exception": false,
     "start_time": "2022-05-14T21:23:06.930304",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Walmart, the retail giant that operates a chain of hypermarkets, wants to understand their weekly sales data, especially the impact from holidays and or big events on the weekly sales data; specifically, Super Bowl, Labor Day, Thanksgiving, and Christmas. In addition, Walmart wants to consider the effect from different macroeconomic/external factors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5b3f21",
   "metadata": {
    "papermill": {
     "duration": 0.130444,
     "end_time": "2022-05-14T21:23:06.028016",
     "exception": false,
     "start_time": "2022-05-14T21:23:05.897572",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd8194f",
   "metadata": {
    "papermill": {
     "duration": 0.130444,
     "end_time": "2022-05-14T21:23:06.028016",
     "exception": false,
     "start_time": "2022-05-14T21:23:05.897572",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "At the end of this session, you will know how to\n",
    "\n",
    "1. Manipulate data of different types using `pandas`\n",
    "1. Visualize data with `matplotlib` and `seaborn` to extract insights \n",
    "1. Perform feature engineering\n",
    "1. Build a pipeline to preprocess data and fit a simple model using `sklearn`\n",
    "\n",
    "*Note: if you see code that's unfamiliar to you, look up for the documentation, and try to understand what it does.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91acd6e9",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1121c77b",
   "metadata": {},
   "source": [
    "- Original sales data were collected from 45 stores across the United States; yet for this session, you will first inspect data from three stores and later focus on just store 1. \n",
    "\n",
    "- Each store is of certain type and size, and there are multiple departments in a store. \n",
    "\n",
    "- The dataset has a temporal component, we ignore this mostly in this session and will discuss time series related techniques later in the cohort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0826745",
   "metadata": {
    "code_folding": [],
    "execution": {
     "iopub.execute_input": "2022-05-14T21:23:07.590761Z",
     "iopub.status.busy": "2022-05-14T21:23:07.590043Z",
     "iopub.status.idle": "2022-05-14T21:23:09.233960Z",
     "shell.execute_reply": "2022-05-14T21:23:09.232902Z",
     "shell.execute_reply.started": "2022-05-14T20:31:16.167193Z"
    },
    "papermill": {
     "duration": 1.783243,
     "end_time": "2022-05-14T21:23:09.234180",
     "exception": false,
     "start_time": "2022-05-14T21:23:07.450937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\" # allow multiple outputs in a cell\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba074fc",
   "metadata": {},
   "source": [
    "## Task I: Load Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385c9537",
   "metadata": {
    "papermill": {
     "duration": 0.131091,
     "end_time": "2022-05-14T21:23:09.496169",
     "exception": false,
     "start_time": "2022-05-14T21:23:09.365078",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Built on top of `numpy`, `pandas` is one of the most widely used tools in machine learning. Its rich features are used for exploring, cleaning, visualizing, and transforming data.  We need to import the library to access all of its features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "419afd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1cc900",
   "metadata": {
    "papermill": {
     "duration": 0.131091,
     "end_time": "2022-05-14T21:23:09.496169",
     "exception": false,
     "start_time": "2022-05-14T21:23:09.365078",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Use `pd.read_csv` to read `train_comb.csv` that contains weekly sales, metadata, and macroeconomic features from three stores into a `pd.DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97ac36cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-14T21:23:09.769778Z",
     "iopub.status.busy": "2022-05-14T21:23:09.769010Z",
     "iopub.status.idle": "2022-05-14T21:23:10.331119Z",
     "shell.execute_reply": "2022-05-14T21:23:10.330499Z",
     "shell.execute_reply.started": "2022-05-14T20:31:17.943779Z"
    },
    "papermill": {
     "duration": 0.705534,
     "end_time": "2022-05-14T21:23:10.331295",
     "exception": false,
     "start_time": "2022-05-14T21:23:09.625761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "filepath = '../dat/train_comb.csv'\n",
    "data = pd.read_csv(filepath) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6093023",
   "metadata": {},
   "source": [
    "Verify that the data is loaded correctly by running `data.head(3)` to see the first few row ( AVOID printing out the entire DataFrame, i.e., `data` or `print(data)`; it might be trivial for small dataset but it can crash your kernel when the dataset is big and slow down the initial data exploration process )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f1febad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Date</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>MarkDown1</th>\n",
       "      <th>MarkDown2</th>\n",
       "      <th>MarkDown3</th>\n",
       "      <th>MarkDown4</th>\n",
       "      <th>MarkDown5</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>24924.50</td>\n",
       "      <td>False</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-12</td>\n",
       "      <td>46039.49</td>\n",
       "      <td>True</td>\n",
       "      <td>38.51</td>\n",
       "      <td>2.548</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.242170</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-19</td>\n",
       "      <td>41595.55</td>\n",
       "      <td>False</td>\n",
       "      <td>39.93</td>\n",
       "      <td>2.514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.289143</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-26</td>\n",
       "      <td>19403.54</td>\n",
       "      <td>False</td>\n",
       "      <td>46.63</td>\n",
       "      <td>2.561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.319643</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-03-05</td>\n",
       "      <td>21827.90</td>\n",
       "      <td>False</td>\n",
       "      <td>46.50</td>\n",
       "      <td>2.625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.350143</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-03-12</td>\n",
       "      <td>21043.39</td>\n",
       "      <td>False</td>\n",
       "      <td>57.79</td>\n",
       "      <td>2.667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.380643</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-03-19</td>\n",
       "      <td>22136.64</td>\n",
       "      <td>False</td>\n",
       "      <td>54.58</td>\n",
       "      <td>2.720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.215635</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-03-26</td>\n",
       "      <td>26229.21</td>\n",
       "      <td>False</td>\n",
       "      <td>51.45</td>\n",
       "      <td>2.732</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.018042</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-04-02</td>\n",
       "      <td>57258.43</td>\n",
       "      <td>False</td>\n",
       "      <td>62.27</td>\n",
       "      <td>2.719</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>210.820450</td>\n",
       "      <td>7.808</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-04-09</td>\n",
       "      <td>42960.91</td>\n",
       "      <td>False</td>\n",
       "      <td>65.86</td>\n",
       "      <td>2.770</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>210.622857</td>\n",
       "      <td>7.808</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  Dept        Date  Weekly_Sales  IsHoliday  Temperature  Fuel_Price  \\\n",
       "0      1     1  2010-02-05      24924.50      False        42.31       2.572   \n",
       "1      1     1  2010-02-12      46039.49       True        38.51       2.548   \n",
       "2      1     1  2010-02-19      41595.55      False        39.93       2.514   \n",
       "3      1     1  2010-02-26      19403.54      False        46.63       2.561   \n",
       "4      1     1  2010-03-05      21827.90      False        46.50       2.625   \n",
       "5      1     1  2010-03-12      21043.39      False        57.79       2.667   \n",
       "6      1     1  2010-03-19      22136.64      False        54.58       2.720   \n",
       "7      1     1  2010-03-26      26229.21      False        51.45       2.732   \n",
       "8      1     1  2010-04-02      57258.43      False        62.27       2.719   \n",
       "9      1     1  2010-04-09      42960.91      False        65.86       2.770   \n",
       "\n",
       "   MarkDown1  MarkDown2  MarkDown3  MarkDown4  MarkDown5         CPI  \\\n",
       "0        NaN        NaN        NaN        NaN        NaN  211.096358   \n",
       "1        NaN        NaN        NaN        NaN        NaN  211.242170   \n",
       "2        NaN        NaN        NaN        NaN        NaN  211.289143   \n",
       "3        NaN        NaN        NaN        NaN        NaN  211.319643   \n",
       "4        NaN        NaN        NaN        NaN        NaN  211.350143   \n",
       "5        NaN        NaN        NaN        NaN        NaN  211.380643   \n",
       "6        NaN        NaN        NaN        NaN        NaN  211.215635   \n",
       "7        NaN        NaN        NaN        NaN        NaN  211.018042   \n",
       "8        NaN        NaN        NaN        NaN        NaN  210.820450   \n",
       "9        NaN        NaN        NaN        NaN        NaN  210.622857   \n",
       "\n",
       "   Unemployment Type    Size  \n",
       "0         8.106    A  151315  \n",
       "1         8.106    A  151315  \n",
       "2         8.106    A  151315  \n",
       "3         8.106    A  151315  \n",
       "4         8.106    A  151315  \n",
       "5         8.106    A  151315  \n",
       "6         8.106    A  151315  \n",
       "7         8.106    A  151315  \n",
       "8         7.808    A  151315  \n",
       "9         7.808    A  151315  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b2ad7d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Date</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>MarkDown1</th>\n",
       "      <th>MarkDown2</th>\n",
       "      <th>MarkDown3</th>\n",
       "      <th>MarkDown4</th>\n",
       "      <th>MarkDown5</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30980</th>\n",
       "      <td>13</td>\n",
       "      <td>99</td>\n",
       "      <td>2012-08-03</td>\n",
       "      <td>90.02</td>\n",
       "      <td>False</td>\n",
       "      <td>81.99</td>\n",
       "      <td>3.512</td>\n",
       "      <td>48280.91</td>\n",
       "      <td>73.92</td>\n",
       "      <td>98.64</td>\n",
       "      <td>13485.99</td>\n",
       "      <td>7765.27</td>\n",
       "      <td>130.737871</td>\n",
       "      <td>5.765</td>\n",
       "      <td>A</td>\n",
       "      <td>219622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30981</th>\n",
       "      <td>13</td>\n",
       "      <td>99</td>\n",
       "      <td>2012-08-10</td>\n",
       "      <td>169.80</td>\n",
       "      <td>False</td>\n",
       "      <td>81.69</td>\n",
       "      <td>3.509</td>\n",
       "      <td>6249.06</td>\n",
       "      <td>70.38</td>\n",
       "      <td>51.09</td>\n",
       "      <td>3258.43</td>\n",
       "      <td>7070.04</td>\n",
       "      <td>130.756161</td>\n",
       "      <td>5.765</td>\n",
       "      <td>A</td>\n",
       "      <td>219622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30982</th>\n",
       "      <td>13</td>\n",
       "      <td>99</td>\n",
       "      <td>2012-08-17</td>\n",
       "      <td>0.08</td>\n",
       "      <td>False</td>\n",
       "      <td>79.40</td>\n",
       "      <td>3.545</td>\n",
       "      <td>5063.08</td>\n",
       "      <td>6.76</td>\n",
       "      <td>40.96</td>\n",
       "      <td>2344.61</td>\n",
       "      <td>5594.85</td>\n",
       "      <td>130.790968</td>\n",
       "      <td>5.765</td>\n",
       "      <td>A</td>\n",
       "      <td>219622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30983</th>\n",
       "      <td>13</td>\n",
       "      <td>99</td>\n",
       "      <td>2012-08-24</td>\n",
       "      <td>90.06</td>\n",
       "      <td>False</td>\n",
       "      <td>77.37</td>\n",
       "      <td>3.582</td>\n",
       "      <td>9360.80</td>\n",
       "      <td>71.92</td>\n",
       "      <td>179.51</td>\n",
       "      <td>8290.49</td>\n",
       "      <td>6291.99</td>\n",
       "      <td>130.838161</td>\n",
       "      <td>5.765</td>\n",
       "      <td>A</td>\n",
       "      <td>219622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30984</th>\n",
       "      <td>13</td>\n",
       "      <td>99</td>\n",
       "      <td>2012-08-31</td>\n",
       "      <td>30.04</td>\n",
       "      <td>False</td>\n",
       "      <td>79.18</td>\n",
       "      <td>3.624</td>\n",
       "      <td>21327.53</td>\n",
       "      <td>50.44</td>\n",
       "      <td>88.44</td>\n",
       "      <td>9444.60</td>\n",
       "      <td>3872.19</td>\n",
       "      <td>130.885355</td>\n",
       "      <td>5.765</td>\n",
       "      <td>A</td>\n",
       "      <td>219622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30985</th>\n",
       "      <td>13</td>\n",
       "      <td>99</td>\n",
       "      <td>2012-09-07</td>\n",
       "      <td>10.10</td>\n",
       "      <td>True</td>\n",
       "      <td>70.65</td>\n",
       "      <td>3.689</td>\n",
       "      <td>17452.15</td>\n",
       "      <td>18.74</td>\n",
       "      <td>69.23</td>\n",
       "      <td>4472.17</td>\n",
       "      <td>5180.78</td>\n",
       "      <td>130.932548</td>\n",
       "      <td>5.765</td>\n",
       "      <td>A</td>\n",
       "      <td>219622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30986</th>\n",
       "      <td>13</td>\n",
       "      <td>99</td>\n",
       "      <td>2012-09-14</td>\n",
       "      <td>0.17</td>\n",
       "      <td>False</td>\n",
       "      <td>68.55</td>\n",
       "      <td>3.749</td>\n",
       "      <td>13208.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.06</td>\n",
       "      <td>1300.16</td>\n",
       "      <td>10484.98</td>\n",
       "      <td>130.977667</td>\n",
       "      <td>5.765</td>\n",
       "      <td>A</td>\n",
       "      <td>219622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30987</th>\n",
       "      <td>13</td>\n",
       "      <td>99</td>\n",
       "      <td>2012-09-21</td>\n",
       "      <td>59.83</td>\n",
       "      <td>False</td>\n",
       "      <td>67.96</td>\n",
       "      <td>3.821</td>\n",
       "      <td>10671.71</td>\n",
       "      <td>141.83</td>\n",
       "      <td>46.00</td>\n",
       "      <td>2465.37</td>\n",
       "      <td>12372.29</td>\n",
       "      <td>131.010333</td>\n",
       "      <td>5.765</td>\n",
       "      <td>A</td>\n",
       "      <td>219622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30988</th>\n",
       "      <td>13</td>\n",
       "      <td>99</td>\n",
       "      <td>2012-10-05</td>\n",
       "      <td>1130.00</td>\n",
       "      <td>False</td>\n",
       "      <td>61.79</td>\n",
       "      <td>3.815</td>\n",
       "      <td>6607.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.60</td>\n",
       "      <td>3943.91</td>\n",
       "      <td>7700.91</td>\n",
       "      <td>131.075667</td>\n",
       "      <td>5.621</td>\n",
       "      <td>A</td>\n",
       "      <td>219622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30989</th>\n",
       "      <td>13</td>\n",
       "      <td>99</td>\n",
       "      <td>2012-10-12</td>\n",
       "      <td>210.00</td>\n",
       "      <td>False</td>\n",
       "      <td>55.10</td>\n",
       "      <td>3.797</td>\n",
       "      <td>1927.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.72</td>\n",
       "      <td>518.97</td>\n",
       "      <td>11269.24</td>\n",
       "      <td>131.108333</td>\n",
       "      <td>5.621</td>\n",
       "      <td>A</td>\n",
       "      <td>219622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Store  Dept        Date  Weekly_Sales  IsHoliday  Temperature  \\\n",
       "30980     13    99  2012-08-03         90.02      False        81.99   \n",
       "30981     13    99  2012-08-10        169.80      False        81.69   \n",
       "30982     13    99  2012-08-17          0.08      False        79.40   \n",
       "30983     13    99  2012-08-24         90.06      False        77.37   \n",
       "30984     13    99  2012-08-31         30.04      False        79.18   \n",
       "30985     13    99  2012-09-07         10.10       True        70.65   \n",
       "30986     13    99  2012-09-14          0.17      False        68.55   \n",
       "30987     13    99  2012-09-21         59.83      False        67.96   \n",
       "30988     13    99  2012-10-05       1130.00      False        61.79   \n",
       "30989     13    99  2012-10-12        210.00      False        55.10   \n",
       "\n",
       "       Fuel_Price  MarkDown1  MarkDown2  MarkDown3  MarkDown4  MarkDown5  \\\n",
       "30980       3.512   48280.91      73.92      98.64   13485.99    7765.27   \n",
       "30981       3.509    6249.06      70.38      51.09    3258.43    7070.04   \n",
       "30982       3.545    5063.08       6.76      40.96    2344.61    5594.85   \n",
       "30983       3.582    9360.80      71.92     179.51    8290.49    6291.99   \n",
       "30984       3.624   21327.53      50.44      88.44    9444.60    3872.19   \n",
       "30985       3.689   17452.15      18.74      69.23    4472.17    5180.78   \n",
       "30986       3.749   13208.43        NaN      28.06    1300.16   10484.98   \n",
       "30987       3.821   10671.71     141.83      46.00    2465.37   12372.29   \n",
       "30988       3.815    6607.14        NaN      50.60    3943.91    7700.91   \n",
       "30989       3.797    1927.15        NaN       9.72     518.97   11269.24   \n",
       "\n",
       "              CPI  Unemployment Type    Size  \n",
       "30980  130.737871         5.765    A  219622  \n",
       "30981  130.756161         5.765    A  219622  \n",
       "30982  130.790968         5.765    A  219622  \n",
       "30983  130.838161         5.765    A  219622  \n",
       "30984  130.885355         5.765    A  219622  \n",
       "30985  130.932548         5.765    A  219622  \n",
       "30986  130.977667         5.765    A  219622  \n",
       "30987  131.010333         5.765    A  219622  \n",
       "30988  131.075667         5.621    A  219622  \n",
       "30989  131.108333         5.621    A  219622  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "817a09f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min date (as string): 2010-02-05\n",
      "Max date (as string): 2012-10-26\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Date</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>MarkDown1</th>\n",
       "      <th>MarkDown2</th>\n",
       "      <th>MarkDown3</th>\n",
       "      <th>MarkDown4</th>\n",
       "      <th>MarkDown5</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>24924.50</td>\n",
       "      <td>False</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3688</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>1085.29</td>\n",
       "      <td>False</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27363</th>\n",
       "      <td>13</td>\n",
       "      <td>55</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>23069.69</td>\n",
       "      <td>False</td>\n",
       "      <td>31.53</td>\n",
       "      <td>2.666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126.442065</td>\n",
       "      <td>8.316</td>\n",
       "      <td>A</td>\n",
       "      <td>219622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20188</th>\n",
       "      <td>4</td>\n",
       "      <td>97</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>38214.05</td>\n",
       "      <td>False</td>\n",
       "      <td>43.76</td>\n",
       "      <td>2.598</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126.442065</td>\n",
       "      <td>8.623</td>\n",
       "      <td>A</td>\n",
       "      <td>205863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20331</th>\n",
       "      <td>4</td>\n",
       "      <td>98</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>12899.52</td>\n",
       "      <td>False</td>\n",
       "      <td>43.76</td>\n",
       "      <td>2.598</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126.442065</td>\n",
       "      <td>8.623</td>\n",
       "      <td>A</td>\n",
       "      <td>205863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3545</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>2293.00</td>\n",
       "      <td>False</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20516</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>46761.90</td>\n",
       "      <td>False</td>\n",
       "      <td>31.53</td>\n",
       "      <td>2.666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126.442065</td>\n",
       "      <td>8.316</td>\n",
       "      <td>A</td>\n",
       "      <td>219622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20659</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>75275.87</td>\n",
       "      <td>False</td>\n",
       "      <td>31.53</td>\n",
       "      <td>2.666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126.442065</td>\n",
       "      <td>8.316</td>\n",
       "      <td>A</td>\n",
       "      <td>219622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3402</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>11737.12</td>\n",
       "      <td>False</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30375</th>\n",
       "      <td>13</td>\n",
       "      <td>95</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>125740.33</td>\n",
       "      <td>False</td>\n",
       "      <td>31.53</td>\n",
       "      <td>2.666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126.442065</td>\n",
       "      <td>8.316</td>\n",
       "      <td>A</td>\n",
       "      <td>219622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Store  Dept        Date  Weekly_Sales  IsHoliday  Temperature  \\\n",
       "0          1     1  2010-02-05      24924.50      False        42.31   \n",
       "3688       1    28  2010-02-05       1085.29      False        42.31   \n",
       "27363     13    55  2010-02-05      23069.69      False        31.53   \n",
       "20188      4    97  2010-02-05      38214.05      False        43.76   \n",
       "20331      4    98  2010-02-05      12899.52      False        43.76   \n",
       "3545       1    27  2010-02-05       2293.00      False        42.31   \n",
       "20516     13     1  2010-02-05      46761.90      False        31.53   \n",
       "20659     13     2  2010-02-05      75275.87      False        31.53   \n",
       "3402       1    26  2010-02-05      11737.12      False        42.31   \n",
       "30375     13    95  2010-02-05     125740.33      False        31.53   \n",
       "\n",
       "       Fuel_Price  MarkDown1  MarkDown2  MarkDown3  MarkDown4  MarkDown5  \\\n",
       "0           2.572        NaN        NaN        NaN        NaN        NaN   \n",
       "3688        2.572        NaN        NaN        NaN        NaN        NaN   \n",
       "27363       2.666        NaN        NaN        NaN        NaN        NaN   \n",
       "20188       2.598        NaN        NaN        NaN        NaN        NaN   \n",
       "20331       2.598        NaN        NaN        NaN        NaN        NaN   \n",
       "3545        2.572        NaN        NaN        NaN        NaN        NaN   \n",
       "20516       2.666        NaN        NaN        NaN        NaN        NaN   \n",
       "20659       2.666        NaN        NaN        NaN        NaN        NaN   \n",
       "3402        2.572        NaN        NaN        NaN        NaN        NaN   \n",
       "30375       2.666        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "              CPI  Unemployment Type    Size  \n",
       "0      211.096358         8.106    A  151315  \n",
       "3688   211.096358         8.106    A  151315  \n",
       "27363  126.442065         8.316    A  219622  \n",
       "20188  126.442065         8.623    A  205863  \n",
       "20331  126.442065         8.623    A  205863  \n",
       "3545   211.096358         8.106    A  151315  \n",
       "20516  126.442065         8.316    A  219622  \n",
       "20659  126.442065         8.316    A  219622  \n",
       "3402   211.096358         8.106    A  151315  \n",
       "30375  126.442065         8.316    A  219622  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Date</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>MarkDown1</th>\n",
       "      <th>MarkDown2</th>\n",
       "      <th>MarkDown3</th>\n",
       "      <th>MarkDown4</th>\n",
       "      <th>MarkDown5</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9920</th>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>36851.92</td>\n",
       "      <td>False</td>\n",
       "      <td>69.16</td>\n",
       "      <td>3.506</td>\n",
       "      <td>2585.85</td>\n",
       "      <td>31.75</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1057.16</td>\n",
       "      <td>1305.01</td>\n",
       "      <td>223.444251</td>\n",
       "      <td>6.573</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19186</th>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>16521.28</td>\n",
       "      <td>False</td>\n",
       "      <td>63.64</td>\n",
       "      <td>3.514</td>\n",
       "      <td>1763.13</td>\n",
       "      <td>88.76</td>\n",
       "      <td>66.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7577.14</td>\n",
       "      <td>131.193097</td>\n",
       "      <td>3.879</td>\n",
       "      <td>A</td>\n",
       "      <td>205863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27505</th>\n",
       "      <td>13</td>\n",
       "      <td>55</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>17414.45</td>\n",
       "      <td>False</td>\n",
       "      <td>46.97</td>\n",
       "      <td>3.755</td>\n",
       "      <td>10192.49</td>\n",
       "      <td>364.57</td>\n",
       "      <td>150.00</td>\n",
       "      <td>1714.15</td>\n",
       "      <td>5563.92</td>\n",
       "      <td>131.193097</td>\n",
       "      <td>5.621</td>\n",
       "      <td>A</td>\n",
       "      <td>219622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9798</th>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>117375.38</td>\n",
       "      <td>False</td>\n",
       "      <td>69.16</td>\n",
       "      <td>3.506</td>\n",
       "      <td>2585.85</td>\n",
       "      <td>31.75</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1057.16</td>\n",
       "      <td>1305.01</td>\n",
       "      <td>223.444251</td>\n",
       "      <td>6.573</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30803</th>\n",
       "      <td>13</td>\n",
       "      <td>97</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>26894.79</td>\n",
       "      <td>False</td>\n",
       "      <td>46.97</td>\n",
       "      <td>3.755</td>\n",
       "      <td>10192.49</td>\n",
       "      <td>364.57</td>\n",
       "      <td>150.00</td>\n",
       "      <td>1714.15</td>\n",
       "      <td>5563.92</td>\n",
       "      <td>131.193097</td>\n",
       "      <td>5.621</td>\n",
       "      <td>A</td>\n",
       "      <td>219622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2400</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>17934.28</td>\n",
       "      <td>False</td>\n",
       "      <td>69.16</td>\n",
       "      <td>3.506</td>\n",
       "      <td>2585.85</td>\n",
       "      <td>31.75</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1057.16</td>\n",
       "      <td>1305.01</td>\n",
       "      <td>223.444251</td>\n",
       "      <td>6.573</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19329</th>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>94014.08</td>\n",
       "      <td>False</td>\n",
       "      <td>63.64</td>\n",
       "      <td>3.514</td>\n",
       "      <td>1763.13</td>\n",
       "      <td>88.76</td>\n",
       "      <td>66.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7577.14</td>\n",
       "      <td>131.193097</td>\n",
       "      <td>3.879</td>\n",
       "      <td>A</td>\n",
       "      <td>205863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29230</th>\n",
       "      <td>13</td>\n",
       "      <td>82</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>31526.31</td>\n",
       "      <td>False</td>\n",
       "      <td>46.97</td>\n",
       "      <td>3.755</td>\n",
       "      <td>10192.49</td>\n",
       "      <td>364.57</td>\n",
       "      <td>150.00</td>\n",
       "      <td>1714.15</td>\n",
       "      <td>5563.92</td>\n",
       "      <td>131.193097</td>\n",
       "      <td>5.621</td>\n",
       "      <td>A</td>\n",
       "      <td>219622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17741</th>\n",
       "      <td>4</td>\n",
       "      <td>67</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>10897.73</td>\n",
       "      <td>False</td>\n",
       "      <td>63.64</td>\n",
       "      <td>3.514</td>\n",
       "      <td>1763.13</td>\n",
       "      <td>88.76</td>\n",
       "      <td>66.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7577.14</td>\n",
       "      <td>131.193097</td>\n",
       "      <td>3.879</td>\n",
       "      <td>A</td>\n",
       "      <td>205863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29373</th>\n",
       "      <td>13</td>\n",
       "      <td>83</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>3955.55</td>\n",
       "      <td>False</td>\n",
       "      <td>46.97</td>\n",
       "      <td>3.755</td>\n",
       "      <td>10192.49</td>\n",
       "      <td>364.57</td>\n",
       "      <td>150.00</td>\n",
       "      <td>1714.15</td>\n",
       "      <td>5563.92</td>\n",
       "      <td>131.193097</td>\n",
       "      <td>5.621</td>\n",
       "      <td>A</td>\n",
       "      <td>219622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Store  Dept        Date  Weekly_Sales  IsHoliday  Temperature  \\\n",
       "9920       1    96  2012-10-26      36851.92      False        69.16   \n",
       "19186      4    87  2012-10-26      16521.28      False        63.64   \n",
       "27505     13    55  2012-10-26      17414.45      False        46.97   \n",
       "9798       1    95  2012-10-26     117375.38      False        69.16   \n",
       "30803     13    97  2012-10-26      26894.79      False        46.97   \n",
       "2400       1    18  2012-10-26      17934.28      False        69.16   \n",
       "19329      4    90  2012-10-26      94014.08      False        63.64   \n",
       "29230     13    82  2012-10-26      31526.31      False        46.97   \n",
       "17741      4    67  2012-10-26      10897.73      False        63.64   \n",
       "29373     13    83  2012-10-26       3955.55      False        46.97   \n",
       "\n",
       "       Fuel_Price  MarkDown1  MarkDown2  MarkDown3  MarkDown4  MarkDown5  \\\n",
       "9920        3.506    2585.85      31.75       6.00    1057.16    1305.01   \n",
       "19186       3.514    1763.13      88.76      66.76        NaN    7577.14   \n",
       "27505       3.755   10192.49     364.57     150.00    1714.15    5563.92   \n",
       "9798        3.506    2585.85      31.75       6.00    1057.16    1305.01   \n",
       "30803       3.755   10192.49     364.57     150.00    1714.15    5563.92   \n",
       "2400        3.506    2585.85      31.75       6.00    1057.16    1305.01   \n",
       "19329       3.514    1763.13      88.76      66.76        NaN    7577.14   \n",
       "29230       3.755   10192.49     364.57     150.00    1714.15    5563.92   \n",
       "17741       3.514    1763.13      88.76      66.76        NaN    7577.14   \n",
       "29373       3.755   10192.49     364.57     150.00    1714.15    5563.92   \n",
       "\n",
       "              CPI  Unemployment Type    Size  \n",
       "9920   223.444251         6.573    A  151315  \n",
       "19186  131.193097         3.879    A  205863  \n",
       "27505  131.193097         5.621    A  219622  \n",
       "9798   223.444251         6.573    A  151315  \n",
       "30803  131.193097         5.621    A  219622  \n",
       "2400   223.444251         6.573    A  151315  \n",
       "19329  131.193097         3.879    A  205863  \n",
       "29230  131.193097         5.621    A  219622  \n",
       "17741  131.193097         3.879    A  205863  \n",
       "29373  131.193097         5.621    A  219622  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at date range of data\n",
    "# check min/max date (as strings):\n",
    "print(f\"Min date (as string): {data['Date'].min()}\\n\"\n",
    "      f\"Max date (as string): {data['Date'].max()}\\n\"\n",
    "     )\n",
    "\n",
    "# double-check by sorting data by 'Date' and looking at head/tail:\n",
    "data_by_date = data.sort_values(by='Date')\n",
    "data_by_date.head(10)\n",
    "data_by_date.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95a6cd41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30990, 16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Store             int64\n",
       "Dept              int64\n",
       "Date             object\n",
       "Weekly_Sales    float64\n",
       "IsHoliday          bool\n",
       "Temperature     float64\n",
       "Fuel_Price      float64\n",
       "MarkDown1       float64\n",
       "MarkDown2       float64\n",
       "MarkDown3       float64\n",
       "MarkDown4       float64\n",
       "MarkDown5       float64\n",
       "CPI             float64\n",
       "Unemployment    float64\n",
       "Type             object\n",
       "Size              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Date</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>MarkDown1</th>\n",
       "      <th>MarkDown2</th>\n",
       "      <th>MarkDown3</th>\n",
       "      <th>MarkDown4</th>\n",
       "      <th>MarkDown5</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19802</th>\n",
       "      <td>4</td>\n",
       "      <td>94</td>\n",
       "      <td>2010-12-03</td>\n",
       "      <td>47999.05</td>\n",
       "      <td>False</td>\n",
       "      <td>46.40</td>\n",
       "      <td>2.727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126.731333</td>\n",
       "      <td>7.127</td>\n",
       "      <td>A</td>\n",
       "      <td>205863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29765</th>\n",
       "      <td>13</td>\n",
       "      <td>90</td>\n",
       "      <td>2012-02-10</td>\n",
       "      <td>127230.25</td>\n",
       "      <td>True</td>\n",
       "      <td>33.73</td>\n",
       "      <td>3.116</td>\n",
       "      <td>9264.48</td>\n",
       "      <td>8292.73</td>\n",
       "      <td>179.72</td>\n",
       "      <td>18849.21</td>\n",
       "      <td>9083.54</td>\n",
       "      <td>130.384903</td>\n",
       "      <td>6.104</td>\n",
       "      <td>A</td>\n",
       "      <td>219622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10295</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-28</td>\n",
       "      <td>30977.96</td>\n",
       "      <td>False</td>\n",
       "      <td>40.60</td>\n",
       "      <td>3.022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127.580032</td>\n",
       "      <td>6.510</td>\n",
       "      <td>A</td>\n",
       "      <td>205863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8147</th>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>2011-04-29</td>\n",
       "      <td>15630.25</td>\n",
       "      <td>False</td>\n",
       "      <td>72.03</td>\n",
       "      <td>3.810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>215.627954</td>\n",
       "      <td>7.682</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14670</th>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>2010-04-30</td>\n",
       "      <td>9278.75</td>\n",
       "      <td>False</td>\n",
       "      <td>53.04</td>\n",
       "      <td>2.787</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126.380567</td>\n",
       "      <td>7.896</td>\n",
       "      <td>A</td>\n",
       "      <td>205863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2718</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>2010-09-10</td>\n",
       "      <td>7966.59</td>\n",
       "      <td>True</td>\n",
       "      <td>78.69</td>\n",
       "      <td>2.565</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.495190</td>\n",
       "      <td>7.787</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12674</th>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>2010-06-11</td>\n",
       "      <td>2835.78</td>\n",
       "      <td>False</td>\n",
       "      <td>78.45</td>\n",
       "      <td>2.668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126.111903</td>\n",
       "      <td>7.896</td>\n",
       "      <td>A</td>\n",
       "      <td>205863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7837</th>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>15132.59</td>\n",
       "      <td>True</td>\n",
       "      <td>48.43</td>\n",
       "      <td>2.943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.404932</td>\n",
       "      <td>7.838</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18403</th>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>2011-07-08</td>\n",
       "      <td>20453.42</td>\n",
       "      <td>False</td>\n",
       "      <td>84.59</td>\n",
       "      <td>3.469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>129.112500</td>\n",
       "      <td>5.644</td>\n",
       "      <td>A</td>\n",
       "      <td>205863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9489</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>2012-05-18</td>\n",
       "      <td>79074.91</td>\n",
       "      <td>False</td>\n",
       "      <td>70.33</td>\n",
       "      <td>3.630</td>\n",
       "      <td>6154.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.11</td>\n",
       "      <td>1675.49</td>\n",
       "      <td>5508.18</td>\n",
       "      <td>221.742674</td>\n",
       "      <td>7.143</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Store  Dept        Date  Weekly_Sales  IsHoliday  Temperature  \\\n",
       "19802      4    94  2010-12-03      47999.05      False        46.40   \n",
       "29765     13    90  2012-02-10     127230.25       True        33.73   \n",
       "10295      4     1  2011-01-28      30977.96      False        40.60   \n",
       "8147       1    80  2011-04-29      15630.25      False        72.03   \n",
       "14670      4    33  2010-04-30       9278.75      False        53.04   \n",
       "2718       1    21  2010-09-10       7966.59       True        78.69   \n",
       "12674      4    19  2010-06-11       2835.78      False        78.45   \n",
       "7837       1    74  2010-12-31      15132.59       True        48.43   \n",
       "18403      4    80  2011-07-08      20453.42      False        84.59   \n",
       "9489       1    93  2012-05-18      79074.91      False        70.33   \n",
       "\n",
       "       Fuel_Price  MarkDown1  MarkDown2  MarkDown3  MarkDown4  MarkDown5  \\\n",
       "19802       2.727        NaN        NaN        NaN        NaN        NaN   \n",
       "29765       3.116    9264.48    8292.73     179.72   18849.21    9083.54   \n",
       "10295       3.022        NaN        NaN        NaN        NaN        NaN   \n",
       "8147        3.810        NaN        NaN        NaN        NaN        NaN   \n",
       "14670       2.787        NaN        NaN        NaN        NaN        NaN   \n",
       "2718        2.565        NaN        NaN        NaN        NaN        NaN   \n",
       "12674       2.668        NaN        NaN        NaN        NaN        NaN   \n",
       "7837        2.943        NaN        NaN        NaN        NaN        NaN   \n",
       "18403       3.469        NaN        NaN        NaN        NaN        NaN   \n",
       "9489        3.630    6154.14        NaN      45.11    1675.49    5508.18   \n",
       "\n",
       "              CPI  Unemployment Type    Size  \n",
       "19802  126.731333         7.127    A  205863  \n",
       "29765  130.384903         6.104    A  219622  \n",
       "10295  127.580032         6.510    A  205863  \n",
       "8147   215.627954         7.682    A  151315  \n",
       "14670  126.380567         7.896    A  205863  \n",
       "2718   211.495190         7.787    A  151315  \n",
       "12674  126.111903         7.896    A  205863  \n",
       "7837   211.404932         7.838    A  151315  \n",
       "18403  129.112500         5.644    A  205863  \n",
       "9489   221.742674         7.143    A  151315  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n",
    "data.dtypes\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85651101",
   "metadata": {},
   "source": [
    "❓ Question 1:\n",
    "\n",
    "Look at the output to get an idea of what each column is and then write a few sentences describing what you notice about the data. You can also use `data.sample(3)` to draw random samples from the data (hints: number of rows and columns, any missing values? data types of the elements? date ranges of the data collected? etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e84e2dd",
   "metadata": {},
   "source": [
    "*Acceptable responses include the number of rows and columns in the dataset, the data types of the elements, how many NaNs there are (and perhaps which columns and/or rows tend to have them), the range of values in each column or other descriptive statistics, some commentary on what this data represents, any initial concerns about how you think we should model this data, or any other commentary you would like to add.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c177f28c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <h4><b><i>Answer:</i></b></h4>\n",
    "    <ul>    \n",
    "    <li>No. rows: 30,990</li>\n",
    "    <li>No. cols: 16</li>\n",
    "    <li>The data spans the time period from 2010-02-05 to 2012-10-26.</li>\n",
    "    <li>It is not clear what the columns 'MarkDown1-5' represent, but they have many missing values 'NaN'.</li>\n",
    "    <li>It is also unclear what the column 'Type' represents, but entries are of dtype object (string, e.g., 'A').</li>\n",
    "    <li>Data types of the remaining columns are what one might expect given the type of information in each column (except perhaps for 'Date', in which entries are dtype object (string) as opposed to e.g. datetime).</li>\n",
    "    <li>The various columns include information that might be relevant to weekly sales, including:\n",
    "        <ul><li>Macroeconomic indicators e.g. 'CPI' or consumer price index, 'Unemployment' (rate): <i>How much disposable income relative to current prices is available?</i></li>\n",
    "            <li>'Temperature' (presumably outside ambient, °F): <i>Is it a pleasant day to shop?</i></li>\n",
    "            <li>'Fuel_price' (presumably USD/gallon of gasoline): <i>How expensive is it to drive to the store?</i></li>\n",
    "            <li>'Size' (I am guessing the store's floor-space shopping area): <i>Does the store have plenty of space to present a wide selection of items as well as hold on-site backup stock? Is the shopping area spacious and e.g., more relaxed, or tightly packed and perhaps stressful? etc.</i></li>\n",
    "            <li>'IsHoliday', a boolean indicating whether the specified weekly intervals include a holiday: <i>Does the specified week include e.g., Black Friday or the busy shopping period around Christmas?</i></li>\n",
    "            <li>A breakdown of weekly sales by specific store and department.<i>...But we do not have the actual location of stores, and for example, associated population density, demographics, household income, road/transportation infrastructure, etc.</i></li>\n",
    "        </ul>\n",
    "    </ul>\n",
    "    \n",
    "Initial concerns regarding the above data include:\n",
    "    <ul><li>We are not given an explicit description of what each column represents (and e.g. in what units). I have made some reasonable assumptions above; but as noted, it remains unclear what columns 'MarkDown1-5' and 'Type' represent.</li>\n",
    "        <li>The absolute magnitude and range/variability of the data differ significantly between columns, suggesting that feature scaling (normalization/standardization) will probably need to be applied. In addition, the 'Date' and 'IsHoliday' columns represent non-continuous, non-quantitative variables.</li>\n",
    "        <li>We haven't yet checked through all the data in detail for example, to make sure that all the data in each column is of the expected data type or that there are no gross errors in data entry.\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2630bb1",
   "metadata": {
    "papermill": {
     "duration": 0.128082,
     "end_time": "2022-05-14T21:23:13.899405",
     "exception": false,
     "start_time": "2022-05-14T21:23:13.771323",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Use `.shape` to inspect the size of the data: sample size and number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16a1ea59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30990, 16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75e6caf",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected Output</summary>\n",
    "(30990, 16)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f56d680",
   "metadata": {},
   "source": [
    "For the following task, we focus on Store `1` only, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dfd053",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_store1 = data[data.Store == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1e1735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check out data_store1:\n",
    "print(f'data_store1 shape is:  {data_store1.shape}')\n",
    "data_store1.head(10)\n",
    "data_store1.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f2e3fa",
   "metadata": {},
   "source": [
    "Retrieve the data from department 9 ( a random choice ) at store 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d606a75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_store1_dept9 = data_store1[data_store1.Dept == 9] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933093ab",
   "metadata": {},
   "source": [
    "Verify the result using `.head()`, `.shape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a5aa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_store1_dept9.head()\n",
    "data_store1_dept9.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e79bb4",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected Output</summary>\n",
    "(143, 16)\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7788c7d",
   "metadata": {},
   "source": [
    "Visualize one full year of sales. The data came with dates sorted, but we can make sure of it and then visualize the first 52 data  points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bb9e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_store1_dept9 = data_store1_dept9.sort_values('Date')\n",
    "data_store1_dept9[['Date', 'Weekly_Sales']].iloc[:52]\\\n",
    "    .set_index('Date').plot(rot=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863382f7",
   "metadata": {},
   "source": [
    "❓ Question 2:\n",
    "\n",
    "Do you have any hypotheses about the holidays' impact on the sales?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4a1b7d",
   "metadata": {},
   "source": [
    "    YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4efef8",
   "metadata": {},
   "source": [
    "**For the purpose of this notebook, we focus on the sales data from Store 1** in DataFrame `df` and is saved in `train_store1.csv`. Let's read in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f836e24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-14T21:23:17.224625Z",
     "iopub.status.busy": "2022-05-14T21:23:17.223574Z",
     "iopub.status.idle": "2022-05-14T21:23:17.230682Z",
     "shell.execute_reply": "2022-05-14T21:23:17.231246Z",
     "shell.execute_reply.started": "2022-05-14T20:31:21.509256Z"
    },
    "papermill": {
     "duration": 0.144233,
     "end_time": "2022-05-14T21:23:17.231443",
     "exception": false,
     "start_time": "2022-05-14T21:23:17.087210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../dat/train-store1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a7d25a",
   "metadata": {},
   "source": [
    "Extract week, month, and year information from the raw `Date` column to better manipulate the weekly data later. Pandas comes with powerful features to make this step easy. Reference: [tutorial\n",
    "](https://pandas.pydata.org/docs/getting_started/intro_tutorials/09_timeseries.html). \n",
    "\n",
    "First, use `.dtypes` to check the datatype of the `Date` column. What's the difference between `df[['Date']]` and `df['Date']`?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b3324b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "df.dtypes\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c7fc60",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected Output</summary>\n",
    "Date    object\n",
    "dtype: object\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d40d97",
   "metadata": {},
   "source": [
    "##### *Using the property `DataFrame.dtypes`, we can see from the above cell that the datatype of the `Date` column is `object`.*\n",
    "This means that the entries in the `Date` column are either strings or alternatively, mixed types. To check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7fd24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import infer_dtype\n",
    "infer_dtype(df.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b049ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Date'] indexes column 'Date', returning a pd.Series\n",
    "df['Date'].dtype\n",
    "df['Date'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990c228a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# However, df[['Date']] indexes/slices returns a single-column data frame having only one column named 'Date':\n",
    "type(df[['Date']])\n",
    "df[['Date']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d9ad3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-14T21:23:18.082947Z",
     "iopub.status.busy": "2022-05-14T21:23:18.082240Z",
     "iopub.status.idle": "2022-05-14T21:23:18.382486Z",
     "shell.execute_reply": "2022-05-14T21:23:18.381861Z",
     "shell.execute_reply.started": "2022-05-14T20:31:21.534163Z"
    },
    "papermill": {
     "duration": 0.464264,
     "end_time": "2022-05-14T21:23:18.382641",
     "exception": false,
     "start_time": "2022-05-14T21:23:17.918377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.Date=pd.to_datetime(df.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fba9947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e84ece0",
   "metadata": {},
   "source": [
    "Verify that the `Date` column's datatype has changed as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786ee438",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Date']].dtypes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20119870",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-14T21:23:18.082947Z",
     "iopub.status.busy": "2022-05-14T21:23:18.082240Z",
     "iopub.status.idle": "2022-05-14T21:23:18.382486Z",
     "shell.execute_reply": "2022-05-14T21:23:18.381861Z",
     "shell.execute_reply.started": "2022-05-14T20:31:21.534163Z"
    },
    "papermill": {
     "duration": 0.464264,
     "end_time": "2022-05-14T21:23:18.382641",
     "exception": false,
     "start_time": "2022-05-14T21:23:17.918377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['week'] = df.Date.dt.week\n",
    "df['month'] = df.Date.dt.month \n",
    "df['year'] = df.Date.dt.year "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0796da36",
   "metadata": {},
   "source": [
    "Verify that now there are 19 columns in `df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f793cb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b6bc64",
   "metadata": {
    "papermill": {
     "duration": 0.133103,
     "end_time": "2022-05-14T21:23:18.998289",
     "exception": false,
     "start_time": "2022-05-14T21:23:18.865186",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "❓ Question 3:\n",
    "\n",
    "Last step before we look deeper into the features is to split the data set into training and testing datasets. Discuss: why do we want to perform EDA only on the training data, not the entire dataset? Shouldn't it be the more the better?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bb470d",
   "metadata": {},
   "source": [
    "    YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081ab5c3",
   "metadata": {},
   "source": [
    "*The answer should mention data leakage, and / or overfitting*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382aab82",
   "metadata": {
    "papermill": {
     "duration": 0.133103,
     "end_time": "2022-05-14T21:23:18.998289",
     "exception": false,
     "start_time": "2022-05-14T21:23:18.865186",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Split the data into training (80%) and test dataset (20%). Use function `train_test_split` from `scikit-learn` ( a popular library for machine learning in Python ),  and set `random_state` to be 42 for reproducibility ( this is not the best way to do train-test-split due to the temporal nature of the data, however, we will ignore it for now )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a348f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e253973d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-14T21:23:19.272142Z",
     "iopub.status.busy": "2022-05-14T21:23:19.271435Z",
     "iopub.status.idle": "2022-05-14T21:23:19.394337Z",
     "shell.execute_reply": "2022-05-14T21:23:19.393604Z",
     "shell.execute_reply.started": "2022-05-14T20:31:21.942121Z"
    },
    "papermill": {
     "duration": 0.26299,
     "end_time": "2022-05-14T21:23:19.394491",
     "exception": false,
     "start_time": "2022-05-14T21:23:19.131501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train, df_test =  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f1046e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-14T21:23:19.272142Z",
     "iopub.status.busy": "2022-05-14T21:23:19.271435Z",
     "iopub.status.idle": "2022-05-14T21:23:19.394337Z",
     "shell.execute_reply": "2022-05-14T21:23:19.393604Z",
     "shell.execute_reply.started": "2022-05-14T20:31:21.942121Z"
    },
    "papermill": {
     "duration": 0.26299,
     "end_time": "2022-05-14T21:23:19.394491",
     "exception": false,
     "start_time": "2022-05-14T21:23:19.131501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Original set  ---> ',df.shape,\n",
    "      '\\nTraining set  ---> ',df_train.shape,\n",
    "      '\\nTesting set   ---> ', df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74698a5f",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected Output</summary>\n",
    "\n",
    "    ```\n",
    "    Original set  --->  (10244, 19) \n",
    "    Training set  --->  (8195, 19) \n",
    "    Testing set   --->  (2049, 19)\n",
    "    ```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7f539f",
   "metadata": {
    "papermill": {
     "duration": 0.133874,
     "end_time": "2022-05-14T21:23:19.663355",
     "exception": false,
     "start_time": "2022-05-14T21:23:19.529481",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Task II: Target, Features, and Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffc1d40",
   "metadata": {},
   "source": [
    "We inspect the datatype of column `Date`; now find datatypes for all columns in `df_train` using `.dtypes`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fcd41a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f94a5ba",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected Output</summary>\n",
    "\n",
    "```\n",
    "Store                    int64\n",
    "Dept                     int64\n",
    "Date            datetime64[ns]\n",
    "Weekly_Sales           float64\n",
    "IsHoliday                 bool\n",
    "Temperature            float64\n",
    "Fuel_Price             float64\n",
    "MarkDown1              float64\n",
    "MarkDown2              float64\n",
    "MarkDown3              float64\n",
    "MarkDown4              float64\n",
    "MarkDown5              float64\n",
    "CPI                    float64\n",
    "Unemployment           float64\n",
    "Type                    object\n",
    "Size                     int64\n",
    "week                     int64\n",
    "month                    int64\n",
    "year                     int64\n",
    "dtype: object\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cd8249",
   "metadata": {},
   "source": [
    "Summary statistics provide you with a general understanding of the data. Use method `.describe()`. By default it reports statistics mean, max, min, quantiles for numerical features and counts, unique, mode for categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90817aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.float_format = \"{:,.2f}\".format\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b4068e",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected Output</summary>\n",
    "\n",
    "```\n",
    "\tStore\tDept\tWeekly_Sales\tTemperature\tFuel_Price\tMarkDown1\tMarkDown2\tMarkDown3\tMarkDown4\tMarkDown5\tCPI\tUnemployment\tSize\tweek\tmonth\tyear\n",
    "count\t8,195.00\t8,195.00\t8,195.00\t8,195.00\t8,195.00\t2,931.00\t2,424.00\t2,878.00\t2,931.00\t2,931.00\t8,195.00\t8,195.00\t8,195.00\t8,195.00\t8,195.00\t8,195.00\n",
    "mean\t1.00\t44.65\t21,865.28\t68.19\t3.22\t8,045.43\t2,961.55\t1,236.83\t3,683.59\t5,023.69\t216.00\t7.61\t151,315.00\t25.89\t6.47\t2,010.96\n",
    "std\t0.00\t29.95\t27,970.00\t14.16\t0.43\t6,484.49\t8,032.30\t7,830.99\t5,849.69\t3,303.07\t4.33\t0.38\t0.00\t14.19\t3.25\t0.80\n",
    "min\t1.00\t1.00\t-863.00\t35.40\t2.51\t410.31\t0.50\t0.25\t8.00\t554.92\t210.34\t6.57\t151,315.00\t1.00\t1.00\t2,010.00\n",
    "25%\t1.00\t20.00\t3,502.09\t57.79\t2.76\t4,039.39\t40.48\t6.00\t577.14\t3,127.88\t211.57\t7.35\t151,315.00\t14.00\t4.00\t2,010.00\n",
    "50%\t1.00\t38.00\t10,357.32\t69.64\t3.29\t6,154.14\t137.86\t30.23\t1,822.55\t4,325.19\t215.46\t7.79\t151,315.00\t26.00\t6.00\t2,011.00\n",
    "75%\t1.00\t72.00\t31,647.36\t80.48\t3.59\t10,121.97\t1,569.00\t101.64\t3,639.42\t6,222.25\t220.64\t7.84\t151,315.00\t38.00\t9.00\t2,012.00\n",
    "max\t1.00\t99.00\t203,670.47\t91.65\t3.91\t34,577.06\t46,011.38\t55,805.51\t32,403.87\t20,475.32\t223.44\t8.11\t151,315.00\t52.00\t12.00\t2,012.0\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9561ad",
   "metadata": {},
   "source": [
    "❓ Question 4:\n",
    "\n",
    "Inspect the output, what are some of your observations?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67b7e01",
   "metadata": {},
   "source": [
    "    YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e70f45",
   "metadata": {},
   "source": [
    "Are there any missing values? Use `.isna()` and `.sum()` to show the number of missing values from each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89849ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5806930",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected Output</summary>\n",
    "\n",
    "```\n",
    "Store              0\n",
    "Dept               0\n",
    "Date               0\n",
    "Weekly_Sales       0\n",
    "IsHoliday          0\n",
    "Temperature        0\n",
    "Fuel_Price         0\n",
    "MarkDown1       5264\n",
    "MarkDown2       5771\n",
    "MarkDown3       5317\n",
    "MarkDown4       5264\n",
    "MarkDown5       5264\n",
    "CPI                0\n",
    "Unemployment       0\n",
    "Type               0\n",
    "Size               0\n",
    "week               0\n",
    "month              0\n",
    "year               0\n",
    "dtype: int64\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226d2c82",
   "metadata": {},
   "source": [
    "What do you think the target variable is in this problem? Assign the column name to `target` for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632db34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c325e9",
   "metadata": {},
   "source": [
    "Visualize the distribution of target variable using `distplot()` from library `seaborn` ( Why seaborn? Check out a comparison between Matplotlib and Seaborn [here](https://analyticsindiamag.com/comparing-python-data-visualization-tools-matplotlib-vs-seaborn/) ). Anything here you observe but the output from `.describe` does not make obvious? Does it follow a normal distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfdecf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.distplot(df_train[target],bins=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6bb611",
   "metadata": {},
   "source": [
    "Notice that there exists nonpositive weekly sales. How many of rows are there that the weekly sales are negative or 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3ff614",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_train[target] <= 0).sum() # Expected Output: 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a5cb2f",
   "metadata": {},
   "source": [
    "What percentage is the negative and zero sales?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ca3264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd0f0ff",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected Output</summary>\n",
    "\n",
    "`0.0015863331299572911` or `0.16%`\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4f87f2",
   "metadata": {},
   "source": [
    "After communicating your findings, the stakeholders confirm that you can remove these data entries for now and they are launching an investigation by analysts and data engineers. \n",
    "\n",
    "Now remove them from the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0f0348",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_train[target] > 0\n",
    "df_train = # YOUR CODE HERE\n",
    "df_train.shape # Expected Output: (8182, 19)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a2db90",
   "metadata": {},
   "source": [
    "Let's move on to features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf5d222",
   "metadata": {},
   "source": [
    "Though almost all the come through as numerical, should they all be treated as numerical features? Let's inspect the number of unique values: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c72b2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(col, df[col].nunique())for col in df_train.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf52e83",
   "metadata": {},
   "source": [
    "`Temperature`, `CPI`, `Unemployment`, `Fuel_Price` are continuous. Those tie to the second business objective. Let us put these four into a list and store it in `external_factors`. From earlier, we noticed that `MarkDownx` columns contain some missing values, we will treat them in a later task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c9ed4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "external_factors = ['Temperature','CPI','Unemployment', 'Fuel_Price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5737d6",
   "metadata": {},
   "source": [
    "Visualize Temperature in a box plot, what do you think is the advantage of a box plot over a histogram? You can use `pd.DataFrame.boxplot()`, set the figure size as (6, 4), and turn off the grid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290e747c",
   "metadata": {},
   "source": [
    "❓ Question 5:\n",
    "\n",
    "Visualize Temperature in a box plot, what do you think the advantage of a box plot over histogram? \n",
    "\n",
    "HINT: You can use `pd.DataFrame.boxplot()`, set the figure size as (6, 4), and turn off the grid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61e2c38",
   "metadata": {},
   "source": [
    "`YOUR ANSWER HERE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79a4a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98178024",
   "metadata": {},
   "source": [
    "Let's visualize all four numerical features in both density plot and box plot. Note any observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8011f033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print('\\033[1mNumeric Features Distribution'.center(100))\n",
    "\n",
    "figsize = (12, 4)\n",
    "\n",
    "n=len(external_factors)\n",
    "colors = ['g', 'b', 'r', 'y', 'k']\n",
    "\n",
    "# histogram\n",
    "plt.figure(figsize=figsize)\n",
    "for i in range(len(external_factors)):\n",
    "    plt.subplot(1,n,i+1)\n",
    "    sns.distplot(df_train[external_factors[i]],\n",
    "                 bins=10, \n",
    "                 color = colors[i])\n",
    "plt.tight_layout();\n",
    "\n",
    "# boxplot\n",
    "plt.figure(figsize=figsize)\n",
    "for i in range(len(external_factors)):\n",
    "    plt.subplot(1,n,i+1)\n",
    "    df_train.boxplot(external_factors[i], grid=False)\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8c8bc4",
   "metadata": {},
   "source": [
    "We will investigate the impacts of the external factors later. Now let's scan through the other features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b165a4",
   "metadata": {},
   "source": [
    "`Store`, `Type`, and `Size` each has only one unique value, offering no information, we can safely ignore them. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b8f257",
   "metadata": {},
   "source": [
    "We extracted `year`, `month`, and `week` from  `Date`, thus `Date` is redundant; but it is easy to find the date range in the training dataset using `Date`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1a58c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Date'].min(), df_train['Date'].max() # Expected Output: (Timestamp('2010-02-05 00:00:00'), Timestamp('2012-10-26 00:00:00'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86745e55",
   "metadata": {},
   "source": [
    "Our training data ranges from 5th of February 2010 to 26th of October 2012."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc93438e",
   "metadata": {},
   "source": [
    "It makes more sense to treat `year`, `month`, `week` as categorical, more accurately ordinal; and the boolean feature `IsHoliday` can be considered as categorical, so can `Dept`. Let's put these column names into a list `categoricalFeatures`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668b91ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricalFeatures = ['year','month','week','IsHoliday', 'Dept']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937c1cdd",
   "metadata": {},
   "source": [
    "For the categorical features, we are more interested in the frequency of each value, use `pd.Series.value_counts` to see how many rows where `IsHoliday` is true and false respectively ( Data imbalance is the norm )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012d208d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af9fc85",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected Output</summary>\n",
    "\n",
    "```\n",
    "False    7586\n",
    "True      596\n",
    "Name: IsHoliday, dtype: int64\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c091c4",
   "metadata": {},
   "source": [
    "Visualize the distribution of `month`; use `sns.countplot()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2077ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbb21d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualising the categorical features \n",
    "\n",
    "print('\\033[1mVisualising Categorical Features:'.center(100))\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "\n",
    "for i in range(len(categoricalFeatures)):\n",
    "    plt.subplot(6,1,i+1)\n",
    "    sns.countplot(df_train[categoricalFeatures[i]])\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3b243b",
   "metadata": {},
   "source": [
    "❓ Question 6: \n",
    "\n",
    "Discuss with your pair programming partner: There is less data in 2012 than the previous two years, did the sale drop from previous years? Does it affect what we see in the plots for month and week? Does the plot below clarify it to some degree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761fe3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=df_train, x=\"week\", y=\"Weekly_Sales\",  style='year');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d9e53a",
   "metadata": {},
   "source": [
    "`YOUR ANSWER HERE`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c9df48",
   "metadata": {},
   "source": [
    "## Task III: Impact from Holidays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8d13d4",
   "metadata": {},
   "source": [
    "The first business objective is to understand the impact of holidays on weekly sales. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f937f9f",
   "metadata": {},
   "source": [
    "There is a flag provided for us: `IsHoliday`, let's calculate the average weekly sales for holiday weeks and non-holiday weeks, respectively. For this, we will use `.groupBy` and `.mean()`. Are holiday sales higher?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0cde2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c06d48a",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected Output</summary>\n",
    "\n",
    "```\n",
    "IsHoliday\n",
    "False   21,756.05\n",
    "True    23,737.05\n",
    "Name: Weekly_Sales, dtype: float64\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78e1c70",
   "metadata": {},
   "source": [
    "But we would like to understand it at more granular level, remember [Simpson's paradox](https://en.wikipedia.org/wiki/Simpson's_paradox)? To save some time,  date mapping are identified for the training data\n",
    "\n",
    "- Super Bowl: 12-Feb-10, 11-Feb-11, 10-Feb-12\n",
    "- Labor Day: 10-Sep-10, 9-Sep-11, 7-Sep-12\n",
    "- Thanksgiving: 26-Nov-10, 25-Nov-11\n",
    "- Christmas: 31-Dec-10, 30-Dec-11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfee7f9",
   "metadata": {},
   "source": [
    "We create a flag for each holiday to help you analyze weekly sale by each holiday type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6193c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "superbowl_mask = df_train['Date'].isin(['2010-02-12', '2011-02-11', '2012-02-10'])\n",
    "laborday_mask = df_train['Date'].isin(['2010-09-10', '2011-09-09','2012-09-07'])\n",
    "thanksgiving_mask = df_train['Date'].isin(['2010-11-26', '2011-11-25'])\n",
    "christmas_mask = df_train['Date'].isin(['2010-12-31', '2011-12-30'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125ace7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['superbowl'] = superbowl_mask\n",
    "df_train['laborday'] = laborday_mask\n",
    "df_train['thanksgiving'] =thanksgiving_mask\n",
    "df_train['christmas'] = christmas_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c936a755",
   "metadata": {},
   "source": [
    "Run the next cell to see 1) how many weekly sales fell on Christmas (does it make sense? what did we not account for?) 2) what is the average weekly sales stratified by whether it is Christmas week or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba7d867",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.groupby(['christmas'])\\\n",
    "        .agg(count = ('christmas', 'size'), \n",
    "             avg_weekly_sales= ('Weekly_Sales','mean'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70af8383",
   "metadata": {},
   "source": [
    "Perform the same for the other three holidays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8c5637",
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays = ['superbowl', 'laborday', 'thanksgiving', 'christmas']\n",
    "for holiday in holidays:\n",
    "    summary_stats = df_train.groupby([holiday])\\\n",
    "        # YOUR CODE HERE\n",
    "        # YOUR CODE HERE\n",
    "    print(summary_stats)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f869aaae",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected Output</summary>\n",
    "\n",
    "```\n",
    "           count  avg_weekly_sales\n",
    "superbowl                         \n",
    "False       8001         21,845.80\n",
    "True         181         24,311.98\n",
    "\n",
    "          count  avg_weekly_sales\n",
    "laborday                         \n",
    "False      8007         21,884.35\n",
    "True        175         22,632.78\n",
    "\n",
    "              count  avg_weekly_sales\n",
    "thanksgiving                         \n",
    "False          8067         21,813.97\n",
    "True            115         27,959.84\n",
    "\n",
    "           count  avg_weekly_sales\n",
    "christmas                         \n",
    "False       8057         21,921.06\n",
    "True         125         20,565.56\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6455d9",
   "metadata": {},
   "source": [
    "Without hypothesis testing and by only eyeballing, it seems like Super Bowl and Thanksgiving has a positive impact on the weekly sales for Store 1 in this training dataset. \n",
    "Discuss with your teammate, are you surprised that during Christmas, sales at Walmart do not go up? Holiday effect, if causal, happened most during Thanksgiving weeks, is this something you expected?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1482d2d4",
   "metadata": {},
   "source": [
    "We have been ignoring `Dept`, let's take a look at the plot below showing the weekly sales by department in 2011. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbbb830",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "sns.scatterplot(data=df_train[df_train.year==2011], x = 'Dept', y= target, hue='IsHoliday');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23615096",
   "metadata": {},
   "source": [
    "Dept 72 has a very unusual high weekly sales during the holiday week, but we will need more data to understand if this is data issue, outlier, or special event. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f16a23e",
   "metadata": {},
   "source": [
    "## Task IV: Visualize Relationship between Macroeconomic & External Factors and Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969b20d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=df_train, x=\"Fuel_Price\", y=\"Weekly_Sales\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfbc301",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=df_train, x=\"Temperature\", y=\"Weekly_Sales\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336d46dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=df_train, x=\"CPI\", y=\"Weekly_Sales\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8696dfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=df_train, x=\"Unemployment\", y=\"Weekly_Sales\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790a2544",
   "metadata": {},
   "source": [
    "By eyeballing, do you find strong evidence that those are correlated with Walmart's weekly sales? Do you think `lineplot` is an appropriate plot for this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185fcd1d",
   "metadata": {},
   "source": [
    "Lastly, we calculate the spearman correlations among target and external factors and verify that there is no strong linear correlation between the target variable and these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edafde35",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "df_train_reduced = df_train[[target] + external_factors]\n",
    "corr = df_train_reduced.corr(method='spearman')\n",
    "heatmap = sns.heatmap(corr.sort_values(by=target, ascending=False),\n",
    "                      vmin=-1, vmax=1, annot=True, fmt='.1g', cmap='BrBG')\n",
    "heatmap.set_title('Features Correlating with Sales Price', fontdict={'fontsize':12}, pad=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6b4c79",
   "metadata": {},
   "source": [
    "## Task V: Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9ecd53",
   "metadata": {},
   "source": [
    "\"*Feature Engineering encapsulates various data engineering techniques such as selecting relevant features, handling missing data, encoding the data, and normalizing it. It is one of the most crucial tasks and plays a major role in determining the outcome of a model.*\" [Ref](https://www.analyticsvidhya.com/blog/2021/10/a-beginners-guide-to-feature-engineering-everything-you-need-to-know/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef295e7",
   "metadata": {},
   "source": [
    "One part of feature engineering is to create new features from given data, like `thanksgiving` column earlier was derived from `Date`. Common techniques for tabular data include to add summary statistics of the numerical features such as mean and standard deviation, to create new features from the interaction of multiple features, etc. In this task, however, we will work on handling missing data, normalizing numerical features, and encoding categorical features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e112542e",
   "metadata": {},
   "source": [
    "First, missing data. Missing value treatment is crucial, yet not trivial. Take a read on [Tackling Missing Value in Dataset](https://www.analyticsvidhya.com/blog/2021/10/handling-missing-value/) for detailed explanation. Features with nulls or wrong values (e.g., negative fuel price) needs to be imputed or removed. \n",
    "\n",
    "- Do you want to keep the features with missing value? Discuss the trade offs\n",
    "- If answer to the first question is yes, then how do you want to impute them? Discuss the trade offs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f42d205",
   "metadata": {},
   "source": [
    "From ealier steps, we observed that only the markdown columns contain missing values, yet we do not have more information on what those values are for.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57607650",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns[df_train.isna().sum() != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ff8e3a",
   "metadata": {},
   "source": [
    "For each column, find out the percentage of the data is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cc0652",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "md_cols = ['MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5']\n",
    "for col in ['MarkDown'+str(i) for i in range(1,6)]:\n",
    "    perc_missing =  # YOUR CODE HERE; perc_missing:float\n",
    "    print (f'{col}: {perc_missing:.0%} is missing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f211b2c4",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected Output</summary>\n",
    "\n",
    "```\n",
    "MarkDown1: 64% is missing\n",
    "MarkDown2: 70% is missing\n",
    "MarkDown3: 65% is missing\n",
    "MarkDown4: 64% is missing\n",
    "MarkDown5: 64% is missing\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546f8286",
   "metadata": {},
   "source": [
    "The majority of the markdown fields are missing. This is where, again, we need to communicate with the stakeholders to understand what the data measure, how the data was collected and then determine our strategy from there. Since we want to understand the impacts of `MarkDownx` on weekly sales, we will keep the features and impute the missing values.  We have learned that there are tradeoffs with how we treat missing values and that our choice of imputation can be significantly impacted by extreme values and the amount of the missing data.  We choose to impute with the median here to mitigate these negative impacts. Use `.fillna()` to impute the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7f45b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE # this works for smaller dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09c0d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_train.isna().sum() != 0).sum() # sanity check: 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5cb0c1",
   "metadata": {},
   "source": [
    "Visualize the distributions for those markdown fields after imputations, are they normal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36d92b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=figsize)\n",
    "for i in range(len(md_cols)):\n",
    "    plt.subplot(1,len(md_cols),i+1)\n",
    "    sns.distplot(df_train[md_cols[i]],\n",
    "                 hist_kws=dict(linewidth=2),\n",
    "                 bins=10, \n",
    "                 color = colors[i])\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c388fccb",
   "metadata": {},
   "source": [
    "Note that missing values are different from outliers. Outliers, on the other hand, are feature values that are rare in nature. They can unncessarily skew the data and causes problem for modeling. Outlier treatment involves removing or imputing such values. One popular approach to identify outliers is IQR; that is, data points that lie 1.5 times of IQR above Q3 (third quartile) and below Q1 (first quartile) are outliers. Take a read on [Detecting and Treating Outliers](https://www.analyticsvidhya.com/blog/2021/05/detecting-and-treating-outliers-treating-the-odd-one-out/). We will leave it as an optional exercise for you to identify outliers using IQR, and replace the outliers with the median."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303270c5",
   "metadata": {},
   "source": [
    "Now let's see how we normalize the data. For numerical features it means scaling the features to be of similar range. This step is crucial for machine learning algorithms that calculate distances between data (e.g., read [The Importance of Feature Scaling](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df6fd06",
   "metadata": {},
   "source": [
    "For this task, of the external features, let's keep Temperature since it is the most linearly correlated with the target variable, though very weak and negative ( feature selection ). In addition, we include one markdown field. Since neither seems to follow normal distributions, it is safer to use `MinMaxScaler` from `sklearn.preprocessing` to transform features by scaling each feature to a given range (See discussion on [Normalization vs Standardization](https://www.analyticsvidhya.com/blog/2020/04/feature-scaling-machine-learning-normalization-standardization/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deef21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "numericalFeatures = ['Temperature', 'MarkDown1']\n",
    "df_train_num = df_train[numericalFeatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69880265",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_num.describe() # Check the summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb15069",
   "metadata": {},
   "source": [
    "Instantiate a MinMaxScaler and fit using `df_train_num`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621dc56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4912f6ee",
   "metadata": {},
   "source": [
    "Now transform training data `df_train_num` and store the resulting nparray in `train_norm`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2f98c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_norm = scaler.transform(df_train_num) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84cf97e",
   "metadata": {},
   "source": [
    "Verify that both columns now have minimum 0 and maximum 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16417a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(train_norm, columns=df_train_num.columns).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17401c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected Output:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b48b3d6",
   "metadata": {},
   "source": [
    "Let's turn to categorical fatures. So far most, if not all Python packages for modeling do not accept strings as input; thus encoding the categorical value to numerical value is a necessary step. Here, let's apply [one-hot encoding](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) on `Dept` and `IsHoliday`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32890ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "categoricalFeatures = ['Dept', 'IsHoliday']\n",
    "df_train_cat = df_train[categoricalFeatures]\n",
    "ohe = OneHotEncoder(handle_unknown='ignore',sparse = False).fit(df_train_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09af8c7e",
   "metadata": {},
   "source": [
    "Transform the categorical features using one hote encoding `ohe`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd52f58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ohe = # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee5766a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ohe.shape, df_train_cat.shape # Expected Output: ((8182, 79), (8182, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85bc5a4",
   "metadata": {},
   "source": [
    "The number of columns explodes from 2 to 79. \n",
    "\n",
    "Lastly we merge the processed numerical features with the processed categorical features using `hstack` in `numpy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7b615c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_train = np.hstack([train_norm, train_ohe])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a93c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape # sanity check: (8182, 81)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de66122",
   "metadata": {},
   "source": [
    "What about the test data? Yes you need to apply the same treatments. We spare some copy + paste + edit and see how this can be done when we introduce `pipeline` next. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc32bead",
   "metadata": {},
   "source": [
    "## Task VI: Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b9d049",
   "metadata": {},
   "source": [
    "Even with less than 20 features in our dataset, there are many many possibilities that you can preprocessing the data. There is no one-fits-all approach; often you will find yourself experimenting with many combinations to achieve better modelling performance: Should I apply normalization or standardization? Do I remove the outliers or should I impute them? Do I impute the missing values with median or mean or 0? Answers to many of these questions is \"It depends.\" (Have you heard [Graduate Student Descent](https://sciencedryad.wordpress.com/2014/01/25/grad-student-descent/)?) That means trial-and-error and it is not efficient to produce a notebook each time when you need to try something slightly different. You will get lost quickly. Pipeline is one useful tool. \n",
    "\n",
    "Not only does Pipeline help streamline the process, keep the code modular, but also reduces the possibility of introducing errors/bugs. In this task, we build the pipeline following the strategies used in the last task, run a simple linear regression model, and print out the model's performance. Note there is minimal code required for you to implement, the key is to understand each step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bcc7db",
   "metadata": {},
   "source": [
    "To avoid confusion, let's read the data again directly from `train-store1.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da8cc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../dat/train-store1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855d4fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5c6682",
   "metadata": {},
   "source": [
    "Separating the target `y` from the features `X`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b50b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop(columns=target), df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519cffb2",
   "metadata": {},
   "source": [
    "Import `Pipeline` from submodule `sklearn.pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88317c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959ee955",
   "metadata": {},
   "source": [
    "Now we build a transformer for numerical features following two steps: impute the missing values with the feature median (use `SimpleImputer`), followed by normalization (use `MinMaxScaler`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0080726d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "numeric_features = ['CPI', 'MarkDown1']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")), \n",
    "    # YOUR CODE HERE\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dd31c6",
   "metadata": {},
   "source": [
    "For categorical features, we apply one hot encoding `OneHotEncoder` ( there are many other options; see [Scikit-learn documentation](https://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features) ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1307a8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['Dept', 'IsHoliday']\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bed811b",
   "metadata": {},
   "source": [
    "Piece the `numeric_transformer` and `categorical_transformer` using `ColumnTransformer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9162e545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5a2dbc",
   "metadata": {},
   "source": [
    "Lastly, let's append the regression model to preprocessing pipeline to complete a full prediction pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69eb8f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"model\", LinearRegression())]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9226da05",
   "metadata": {},
   "source": [
    "The pipepline has been built! The rest is to \n",
    "- split the data into training and testing sets\n",
    "- apply the pipeline to the training data\n",
    "- obtain the prediction performance on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ba7499",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64369e9f",
   "metadata": {},
   "source": [
    "Let's run the prediction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb720cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63956599",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"model score: %.3f\" % model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254275d1",
   "metadata": {},
   "source": [
    "Optional: Discuss what type of [Feature Selection](https://scikit-learn.org/stable/modules/feature_selection.html#feature-selection) strategy you would use to select the features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219b9f63",
   "metadata": {},
   "source": [
    "## Automating EDA\n",
    "\n",
    "In this exercise, you have learned the manual way to perform EDA.  Doing EDA manually has the benefits of customization, but is also highly repetitive.  For this reason, a lot of EDA can easily be automated!  In automating our EDA, we can get to know our data more quickly and spend more time on feature engineering and modeling.  Let's check out a library called [SweetViz](https://github.com/fbdesignpro/sweetviz) to see how we can automate EDA! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3ba419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sweetviz as sv\n",
    "\n",
    "orig_data_report = sv.analyze(df)\n",
    "orig_data_report.show_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599e143f",
   "metadata": {},
   "source": [
    "1. Click on a feature to tab to explore the feature in more detail.\n",
    "1. Notice that `SweetViz` calculates the descriptive stats for each feature, along with its missing and duplicate value stats.\n",
    "1. Notice that `SweetViz` helps to detect numerical vs categorical datatypes.\n",
    "1. Click on the `ASSOCIATIONS` tab to explore associations/correlations!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d63c8f",
   "metadata": {},
   "source": [
    "### Prefer a browswer experience?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab635869",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_data_report.show_html('orig_data_report.html', open_browser=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d469ed93",
   "metadata": {},
   "source": [
    "### Now let's have a look at a comparison report of our train and test datasets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ef0c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_report = sv.compare([X_train, 'Train'], [X_test, 'Test'])\n",
    "compare_report.show_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d54a44",
   "metadata": {},
   "source": [
    "## Note"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba537f84",
   "metadata": {},
   "source": [
    "- EDA, like other parts of machine learning, is an iterative process, NOT linear.\n",
    "- This analysis is far from being comprehensive; rather it is a starting point. \n",
    "- There does not exist one \"standard\" way to perform EDA. You should always keep business objectives in mind and perform analysis as seen fit. It is one of those skills that grows with lots of practices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa37a7e2",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0deab61a",
   "metadata": {},
   "source": [
    "1. Original dataset is from [kaggle: wallmart sales forecast datasets](https://www.kaggle.com/datasets/iamprateek/wallmart-sales-forecast-datasets)\n",
    "2. Notebook: [craking the walmart sales forecasting challenge](https://www.kaggle.com/code/fernandol/cracking-the-walmart-sales-forecasting-challenge)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (wm39j)",
   "language": "python",
   "name": "wm39j"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 659.006746,
   "end_time": "2022-05-14T21:33:54.545503",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-14T21:22:55.538757",
   "version": "2.3.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "620px",
    "left": "56px",
    "top": "110px",
    "width": "279px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "c57794392b841cffd8686d5c4548e4e2ec78521f49300d60954d1380f1b4bd1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
